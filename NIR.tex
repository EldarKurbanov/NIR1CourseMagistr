% !TeX spellcheck = ru_RU
%% -*- coding: utf-8 -*-
\documentclass[14pt,a4paper]{scrartcl} 
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{indentfirst}
\usepackage{misccorr}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage{makecell,array}
\usepackage{url}
\usepackage{breakurl}
\usepackage[breaklinks]{hyperref}
\usepackage{minted}
\usepackage{textcomp}
\usepackage{comment}
\usepackage{tabularx,booktabs} 
\usepackage{multirow}

\graphicspath{{images/}}

% "Прокаченные" типы колонок для LaTeX. Умеют выравнивать содержимое столбца по горизонтали и принимать фиксированный размер. Полезная вещь.
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}} % Выравнивание по левому краю.
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}} % Выравнивание по середине.
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}} % Выравнивание по правому краю.


% Тоже самое, но ещё с отступом слева от текста (выравнивание по середине)
\newcommand\superunderlinec[3]{$\underset{\text{#3}}{\text{\underline{\hspace{#2}#1\hspace{#2}}}}$}

%Настройки для того, чтобы была возможность переносить строки внутри таблиц. Подробнее здесь:  https://tex.stackexchange.com/questions/2441/how-to-add-a-forced-line-break-inside-a-table-cell
\renewcommand\theadalign{bc}
\renewcommand\theadfont{\normalfont}
\renewcommand\theadgape{\Gape[0pt]}
\renewcommand\cellgape{\Gape[0pt]}

\begin{document}
\begin{titlepage}
	\begin{center}
	    Федеральное государственное автономное \\ 
	    образовательное учреждение высшего образования \\
	    «Волгоградский государственный университет» \\
	    
	    \vspace{0.3cm}
	    
	    институт Математики и информационных технологий
	    
	    кафедра Компьютерных наук и экспериментальной математики
	    \vspace{1.5cm}
	    
	    \newlength{\MLL}
		\settowidth{\MLL}{«\underline{\hspace{2.5cm}}» \underline{\hspace{2cm}}}
	
		\hfill\begin{minipage}{0.4\textwidth}
	 		Допустить работу к защите \\
	 		Зав. каф. КНЭМ \\
	 	 	\underline{\hspace{3.5cm}}В.А.Клячин \\
	  		<<\underline{\hspace{1cm}}>>\underline{\hspace{3.0cm}} 2021 г. 
		\end{minipage}
		
	    \vspace{1.5cm}	
	
	    Курбанов Эльдар Ровшанович
	    
	    \begin{spacing}{1.3}
    	    	\textbf{Система управления и формирования поведенческой стратегии автономного мобильного робота}
	    \end{spacing}
	    
	    Отчёт о научно-исследовательской работе
	\end{center}

	\vfill
	
	\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}
	
	\renewcommand{\arraystretch}{2}
	
	\begin{tabular}{C{4cm}C{8cm}c }
			Студент & Курбанов Э.Р &  \superunderlinec{\thead{\normalfont{}}}{1.9cm}{(дата, подпись)}
			\vspace{0.6cm} \\
			Специальность & \thead{\normalfont{Математическое обеспечение} \\ \normalfont{и администрирование} \\ \normalfont{информационных систем}}  \\
			Группа & МОСм-201 & \\
			Научный руководитель & \thead{д.ф.-м.н., зав. каф. КНЭМ \\ В.А.Клячин} &  \superunderlinec{\thead{\normalfont{}}}{1.9cm}{(дата, подпись)} \\
			Нормоконтролер & \underline{\hspace{4cm}} & \superunderlinec{\thead{\normalfont{}}}{1.9cm}{(дата, подпись)}
		\end{tabular}
	
	\vfill
	
	\begin{center}
	  Волгоград 2021
	\end{center}
	
	\clearpage
	
	\begin{center}
	    Федеральное государственное автономное \\ 
	    образовательное учреждение высшего образования \\
	    «Волгоградский государственный университет» \\
	    
	    \vspace{0.3cm}
	    
	    институт Математики и информационных технологий
	    
	    кафедра Компьютерных наук и экспериментальной математики
	    \vspace{1.5cm}
	    
	    %\newlength{\MLL}
		%\settowidth{\MLL}{«\underline{\hspace{2.5cm}}» \underline{\hspace{2cm}}}
	
		\hfill\begin{minipage}{0.4\textwidth}
			УТВЕРЖДАЮ \\
	 		Руководитель направления \\
	 	 	\underline{\hspace{6cm}} \\
			\underline{\hspace{6cm}} \\
	  		<<\underline{\hspace{1cm}}>>\underline{\hspace{3.0cm}} 2021 г. 
		\end{minipage}
		
	    \vspace{1.5cm}	
	
	    ЗАДАНИЕ \\
	    на научно-исследовательскую работу студента \\
	    Курбанова Эльдара Ровшановича МОСм-201 \\
	    
	    \begin{enumerate}
	    
	    	\item Тема: Система управления и формирования поведенческое стратегии автономного мобильного работа;
		\item Цель: Изучить возможные реализации системы управления и формирования поведенческой стратегии автономного мобильного робота;
		\item Основные задачи:
		\begin{enumerate}
			\item Ознакомление с предметной областью и сферой применения;
			\item Обзор и изучение инструментов для создания системы управления роботом и формирования его поведенческой стратегии, реализованные в высокоуровневом фрейворке ROS\footnote{ROS - Robot Opetaing System};
		\end{enumerate}
		
		\item Основные этапы выполнения работы:
		\begin{enumerate}
			\item Знакомство с основными понятиями предметной области;
			\item Изучение существующих реализаций систем управления роботом для ROS и изучение его основных возможностей;
		\end{enumerate}
		
		\item Рекомендуемая литература:
		\begin{enumerate}
			\item Книжка по ROS;
			\item Книжка по ROS;
			\item Книжка по ROS;
		\end{enumerate}
	    
	    \end{enumerate}
	    
	\end{center}
	\noindentДата выдачи: \underline{\hspace{4cm}} Срок выполнения: \underline{\hspace{4cm}}
	\vspace{0.5cm} \\
	Руководитель: \superunderlinec{\thead{\normalfont{}}}{2cm}{(подпись)} д.ф.-м.н., зав. каф. КНЭМ, В.А.Клячин \\
	Задание принял к исполнению:  \superunderlinec{\thead{\normalfont{}}}{3cm}{(подпись)}

	\vfill

\end{titlepage}

\tableofcontents
\newpage

\section{Введение}

	\subsection{Цель работы}
	
		Целью данной работы является ознакомление читателя с некоторыми решениями задач по распознаванию лиц на встраиваемых системах. Из-за некоторых требований к встраиваемым системам, такие как мобильность, малая размерность, низкое энергопотребление в сочетании с низкой производительностью реализация решения данной задачи несколько усложняется и иногда нужно искать обходные пути. 
		
		В данной работе будет представлено решение задачи распознавания лиц на отечественном встраиваемом компьютере ELISE-3D и на одном из самых популярных зарубежных решений в области встраиваемых компьютеров – Raspberry PI 3 Model B.

	%\subsection{Задача распознавания лиц}
	
		%Задача распознавания заключается в выделении некоторого объекта на входных данных, будь это картинка или видео-поток, а также попытка с какой-либо вероятностью сказать, чем является данный объект и какие у него параметры. В частности, после распознания лица по нему же самому можно выделить ещё несколько ключевых параметров, которые можно выделить, проанализировав обнаруженное лицо (например, можно определить пол, возраст, эмоция и т.д.). 
		
		\subsection{Задача распознавания лиц}
		
			Задача автоматического распознавания лиц в реальном времени была поставлена ещё в прошлом веке, и сегодня она прекрасно реализована и используется во многих программно-аппаратных комплексах, в том числе и мобильных приложениях.
			
			Технология распознавания лиц достигла невероятно высокого уровня: стало возможным распознавать конкретных людей, в том числе, в очках и головных уборах. Этот метод идентификации признан настолько точным, что он уже начал вытеснять обычные способы идентификации с помощью пароля, например, при совершении банковских платежей\cite{bib:Smart_Payment_China}. 
			
			Однако мы не будем решать задачу идентификации личности по лицу. Разработка системы распознавания конкретных лиц требует специфичной выборки (тренировочных данных) для данной задачи, содержащей определённых лиц, которых мы и хотим распознавать. Образцы должны быть хорошими для качественного обнаружения. Создание такой выборки для конкретных людей - очень длительный и дорогой процесс (поскольку требуется много фотографий этих людей в разных ситуациях). При создании образца для простого распознавания любых лиц намного проще и быстрее, так как мы можем сделать большую учебную выборку, используя данные из сети Интернет.
			
			На входящем видео-потоке мы распознаем лицо, попробуем угадать пол, возраст человека, а также его текущую эмоцию. Решение этой задачи - один из этапов проектирования будущего робота, который самостоятельно распознавать данные характеристики\cite{bib:Elise_CPU_Desc}.
		
		%\subsubsection{Распознавание объектов}
		
		%	Для проектирования будущего робота также необходимо решить и более общую задачу распознавания - распознавание объектов. При движении робот должен уметь распознавать людей и другие объекты окружающей среды в режиме реального времени. Такое умение, иногда, будет спасать ему <<жизнь>>\cite{bib:Driaba_NIR}.

\section{Отечественное аппаратное решение}

	Для  решения задачи будем использовать отладочную плату ELISE-3D на базе процессора ELISE предоставленную Волгоградскому Государственному Университету компанией Элвис.
	
	\subsection{Спецификации ELISE-3D}
	
		ELISE-3D представляет собой стереокамеру со встроенной системой видеоаналитики. Модуль может использоваться для различных применений, требующих 3D анализ сцен и объектов, таких как системы безопасности, мобильные роботы и т.д. На модуле имеется 2 видеокамеры, выход USB для подключения Flash-накопителя с Buildroot, разъём Ethernet и вход питания на 12 вольт. Задняя часть ELISE-3D - это большой радиатор для отведения тепла. Фотографии можно найти на рисунке \ref{fig:ELISE-3D}\cite{bib:Chuprikov_NIR}.
		
		\begin{figure}[H]
			\begin{minipage}[h]{0.47\linewidth}
				\center{\includegraphics[width=1\linewidth]{Elise_1.jpg}} \hspace{0.1cm} \\
			\end{minipage}
			\hfill
			\begin{minipage}[h]{0.47\linewidth}
				\center{\includegraphics[width=1\linewidth]{Elise_2.jpg}} \hspace{0.1cm} \\
			\end{minipage}
			\vfill
			\begin{minipage}[h]{0.47\linewidth}
				\center{\includegraphics[width=1\linewidth]{Elise_3.jpg}} \\
			\end{minipage}
			\hfill
			\begin{minipage}[h]{0.47\linewidth}
				\center{\includegraphics[width=1\linewidth]{Elise_4.jpg}} \\
			\end{minipage}
			\caption{ELISE-3D.}
			\label{fig:ELISE-3D}
		\end{figure}
	
		\subsubsection{Процессор ELISE}
		
			Процессор ELISE - это мультиплатформенная система на кристалле с технологическим процессом 28 нм, ориентированный на интернет вещей и мультимедиа.
			
			Система на кристалле ELISE объединяет широкий набор многофункциональных IP-блоков, включая блоки предварительной и последующей обработки стерео видеоизображений со сверхвысоким разрешением, несколько ядер центральных процессоров для выполнения задач разной степени интенсивности. Структуру можно увидеть на рисунке \ref{fig:Elise_Scheme}\cite{bib:Elise_CPU_Desc}.
			
			\begin{figure}[h]
				\center{\includegraphics[height=6cm]{Elise_chip_scheme.jpg}}
				\caption{Структура системы на кристалле ELISE.}
				\label{fig:Elise_Scheme}
			\end{figure}
			
			Основные спецификации процессора:
			
			\begin{itemize}
				\item Рабочая частота (0.9 В/ +85\textdegree{}C)
					\subitem 1.2 ГГц Apache P5607 (CPU0)
					\subitem 1.0 ГГц Intel Aptiv (CPU1)
					\subitem 600 МГц MIPS M5150 Virtuoso (CPU2)
				\item Память на кристалле: Boot ROM 64 кбайт; System SRAM 128 кбайт; OTP 4 кбайт;
				\item Память, адресуемая микросхемой - DDR до 3.5 Гбайт
				\item Система управления питанием
				\item Встроенные датчики температуры и напряжения
				\item Процессор изображений PowerVR V2500 Felix, два потока
				\item Видеоэнкодер PowerVR E4500 Onyx, поддерживаемые форматы: H.264, MPEG-4, MPEG-2.
				\item Видеодекодер PowerVR D5500 Coral
			\end{itemize}
		
			Основной частью чипа является 8-ми ядерный DSP-кластер Elvees VELCore02, представляющий собой набор ядер для обработки видеосигнала. Предоставленные драйверы для данного устройства содержат интерфейсы для работы с OpenCL и OpenVX. OpenCV, к сожалению, отсутствует и использовать его здесь невозможно.
		
	\subsection{Программное обеспечение}
	
		ELISE-3D предоставляется с операционной системой на базе Buildroot. Это бесплатный набор Make-файлов и патчей с открытым исходным кодом, упрощающих и автоматизирующих процесс создания загружаемой среды Linux. Buildroot использует кросс-компиляцию, позволяющую ему создавать несколько целевых платформ в одной системе. Buildroot может автоматически собрать необходимый набор инструментов кросс-компиляции, создать корневую файловую систему, скомпилировать образ ядра Linux и сгенерировать загрузчик для целевой встроенной системы.
		
		В первую очередь система предназначена для использования с небольшими или встроенными системами, основанными на различных компьютерных архитектурах. Множество стандартных библиотек C поддерживаются как часть набора инструментов, включая библиотеку GNU C, uClibc и musl, а также стандартные библиотеки C, которые принадлежат к различным предварительно настроенным средам разработки, таким как предоставляемые Linaro\cite{bib:Buildroot_Wikipedia}. 
		
		В сборку ELISE-3D вошло не так много программ. Из ключевого можно отметить присутствие свободной библиотеки компьютерного зрения OpenVX и интерпретатора Python версии 2.7.
		
	\subsection{Метод Виолы-Джонса}
	
		Метод Виолы-Джонса - это первая инфраструктура обнаружения лиц, которая обеспечивает быстрое обнаружение лиц в режиме реального времени. Этот метод в 2001 году был предложен Полом Виолой и Майклом Джонсом\cite{bib:Viola-Jones_Wikipedia}.
	
		\subsubsection{Принцип работы}
		
			Признаки, используемые алгоритмом, опираются на суммирование пикселей из прямоугольных регионов. Сами признаки несколько напоминают признаки Хаара, которые ранее также использовались для поиска лиц на изображениях. На рисунке \ref{fig:Viola-Jones_types} показаны четыре различных типа признаков. Величина каждого вычисляется как сумма пикселей в белых прямоугольниках, из которой затем вычитается сумма пикселей в чёрных областях\cite{bib:Viola-Jones_Wikipedia_Ru}.
			
			\begin{figure}[h]
				\center{\includegraphics[height=6cm]{Viola-Jones_types.png}}
				\caption{Типы «признаков», использованные в алгоритме.}
				\label{fig:Viola-Jones_types}
			\end{figure}
		
			На этапе обнаружения в методе Виолы — Джонса окно установленного размера движется по изображению, и для каждой области изображения, над которой проходит окно, рассчитывается признак Хаара. Наличие или отсутствие предмета в окне определяется разницей между значением признака и обучаемым порогом. Поскольку признаки Хаара мало подходят для обучения или классификации (качество немного выше чем у случайной нормально распределенной величины), для описания объекта с достаточной точностью необходимо большее число признаков. Поэтому в методе Виолы — Джонса признаки Хаара организованы в каскадный классификатор\cite{bib:Haar_Wikipedia}.
			
		\subsubsection{Построение каскадов Хаара}
		
			Для обучения каскада необходимо построить обучающую выборку в определённом формате. Алгоритм обучения каскада уже реализован в составе графического фреймворка OpenCV. Для обучения необходимо воспользоваться такими инструментами, как opencv\_traincascase и opencv\_traincascase. 
			
			Программа Createsamples подготавливает набор <<хороших>> изображений, приводя этот набор к общему формату путём выделения областей, на которых есть искомое лицо с учётом его пропорций на картинке. Программа Traincascade на основе полученных данных создаёт каскад из признаком Хаара, который и будет использоваться для распознавания лиц при помощи метода Виолы-Джонса.
			
			Инструментам из OpenCV требуется обучающая выборка, записанная в определённом формате. Необходимо создать два списка с изображениями - <<плохими>> и <<хорошими>>. Список <<хороших>> помимо пути к фотографии лиц должен содержать количество искомых лиц на изображении, а также координаты прямоугольников, в рамках которого искомые лица и содержатся\cite{bib:Chuprikov_NIR}.
			
			На данный момент самым лучшим решением для создания такого специализированного формата списков является кроссплатформенный инструмент GlmE3000, созданный бывшим студентом Волгоградского Государственного Университета Вячеславом Чуприковым. Принцип работы программы очень прост: необходимо указать некоторую <<рабочую>> папку, в которой уже должны содержаться файлы Good.dat и Bad.dat (в самом начале они пустые), а также папки Bad и Good с соответствующими фотографиями внутри. Далее, в самой программе, работающей на оконном фреймворке Swing необходимо на каждой <<хорошей>> фотографии выделять искомое лицо или объект (программа универсальна). Таким образом после работы программы и оператора за компьютером, выделяющего в прямоугольник лица мы получаем заполненные файлы Good.dat и Bad.dat, готовые для работы с инструментами библиотеки OpenCV. Интерфейс программы показан на рисунке \ref{fig:Glme_3000}.
			
			\begin{figure}[h]
				\center{\includegraphics[height=6cm]{Glme_3000.jpg}}
				\caption{Интерфейс программы GlmE3000.}
				\label{fig:Glme_3000}
			\end{figure}
		
		\subsubsection{OpenVX}
		
			OpenVX - это открытый, бесплатный лицензионный стандарт для кроссплатформенного ускорения приложений компьютерного зрения. Стандарт разработан Khronos Group для облегчения портативной, оптимизированной и энергоэффективной обработки методов для алгоритмов компьютерного зрения. OpenVX использует связное графическое представление операций и является дополнением к библиотеке OpenCV с открытым исходным кодом. В некоторых приложениях платформа предлагает более оптимизированное управление графиками, чем OpenCV\cite{bib:OpenVX_Wikipedia}. Структура распознавания лиц с двух видео-камер описана в рисунке \ref{fig:Stereo_Vision_OpenVX}\cite{bib:OpenVX_Habr}.
			
			\begin{figure}[h]
				\center{\includegraphics[height=6cm]{Stereo_Vision_OpenVX.jpg}}
				\caption{Распознавание на OpenVX с двух видео-потоков.}
				\label{fig:Stereo_Vision_OpenVX}
			\end{figure}
			
	
	\subsection{Распознавание объекта}
	
		Полноценного распознавания на данном аппарате в данный момент добиться не удалось. Программа распознавания лиц, предоставленная компанией Элвис, использующая метод Виолы-Джонса реализована не до конца в следствии проблем с производительностью самой отладочной платы и в следствии довольно сложного процесса разработки из-за особенностей Buildroot. Дело в том, что для тестирования какой-либо части программы необходимо заново скомпилировать весь Buildroot, затем, получив образ системы, закачать его на Flash-накопитель и только после этого протестировать. Такой подход не удобен, так как занимает довольно продолжительное время для решения даже самых маленьких задач.
		
		В данный момент программа умеет в качестве аргумента принимать входное изображение в формате ppm и выдавать время обработки данного изображения. Пример результата работы программы можно увидеть на рисунке \ref{fig:Viola-Jones_Putty}.
		
		\begin{figure}[h]
			\center{\includegraphics[height=6cm]{Viola-Jones_Putty.jpg}}
			\caption{Пример работы программы elcore40-viola-jones.}
			\label{fig:Viola-Jones_Putty}
		\end{figure}
	
	\subsection{Результат}
	
		На данном этапе отечественному аппаратному решению требуется серьёзная доработка. В текущем виде оно не пригодно к использованию для распознавания лиц. К сожалению, компания Элвис <<заморозила>> проект. Основной причиной стала слабая производительность системы.

\section{Зарубежное аппаратное решение}

	Поскольку нашей общей задачей является создание мобильного автономного робота с видеоаналитикой, мы предъявляем к оборудованию следующие требования:
	\begin{itemize}
		\item Мобильность;
		\item Компактность;
		\item Низкое энергопотребление.
	\end{itemize}
	
	Было принято решение использовать Raspberry Pi 3 Model B - одноплатный мини-компьютер, показанный на рисунке \ref{fig:PI1}.
	
	\begin{figure}[h]
		\center{\includegraphics[height=6cm]{PI1.jpg}}
		\caption{Raspberry PI Model 3 Model B.}
		\label{fig:PI1}
	\end{figure}

	\subsection{Спецификации Raspberry PI 3 Model B}
	
		Raspberry PI 3 Model B - это одноплатный компьютер размером с банковскую карту. Он предназначен для обучения программированию и способен выполнять самые различные задачи\cite{bib:Raspberry_PI_Product_Page}.
		\newline \newline
		Характеристики:
		\begin{itemize}
			\item Четырехъядерный процессор 1,2 ГГц Broadcom BCM2837 64-битный процессор;
			\item 1 ГБ оперативной памяти;
			\item Наличие беспроводной локальной сети BCM43438 и Bluetooth Low Energy;
			\item Ethernet 100 мб/с;
			\item 40-контактный удлиненный GPIO;
			\item 4 USB версии 2.0;
			\item 4-х контактый стереовыход и композитный видеопорт;
			\item Полноразмерный HDMI для подключения видеовыхода;
			\item Порт камеры CSI для подключения камеры Raspberry Pi;
			\item Порт дисплея DSI для подключения сенсорного дисплея Raspberry Pi;
			\item Порт Micro SD для загрузки операционной системы и хранения данных;
			\item Модернизированный коммутируемый источник питания Micro USB до 2,5 А.
		\end{itemize}
	
	\subsection{Программное обеспечение}
	
		Компьютер работает с MicroSD карты на свободной операционной системе Raspbian 9, основанной на Debian. В ней есть полноценный рабочий стол, можно запускать любые программы, скомпилированные под платформу Linux ARM. В репозиториях (apt-get) имеется большое количество программ доступных для скачивания и работы. Система использует менеджер пакетов dpkg\cite{bib:Raspbian_Specs}.
	
	\subsection{Дополнительная вычислительная мощность}
	
		Распознавание лица в режиме реального времени на Raspberry Pi 3 Model B работает плохо, производя менее 1 кадра в секунду\cite{bib:Raspberry_Face_Recognition}. В связи с этим, мы будем вынуждены использовать дополнительные вычислительные мощности. В качестве дополнительного вычислительного устройства было решено использовать недавно (ноябрь 2018 г.) выпущенный Intel Neural Compute Stick 2, показанный на рисунке \ref{fig:NCS1}. 
		
		\begin{figure}[h]
			\center{\includegraphics[height=5cm]{NCS1.jpg}}
			\caption{Intel Neural Compute Stick 2.}
			\label{fig:NCS1}
		\end{figure}
	
		%\subsubsection{Принцип работы Intel Neural Compute Stick 2}
		
		%\subsubsection{Преимущества данного выбора}
	
	\subsection{Глубокие свёрточные нейросети}
	
		Задачу распознавания будем решать с помощью глубоких многослойных нейронных сетей. В слоях такой сети сама свёртка чередуется с субдискретизацией (пулингом). Такая архитектура позволяет распознавать признаки со сложной иерархией. Структура таких сетей всегда многослойна, однонаправлена, слои не имеют обратной связи. При обучении нейронной сети используется метод обратного распространения ошибки. Архитектура типичной свёрточной нейронной сети показана на рисунке \ref{fig:Typical_CNN}\cite{bib:Deep_Conv_Network_Wiki}.
	
		%Требуется дополнение раздела
		
		\begin{figure}[h]
			\center{\includegraphics[width=1\linewidth]{Typical_CNN.png}}
			\caption{Типовая архитектура свёрточной нейронной сети.}
			\label{fig:Typical_CNN}
		\end{figure}
		
		%\subsubsection{Принцип работы свёрточных нейросетей}
	
	\subsection{Инструментарий OpenVINO}
	
		OpenVINO - это инструментарий для разработки программного обеспечения под платформу Intel, и его аббревиатура означает - открытый визуальный вывод и оптимизатор нейронной сети. Он содержит инструментарий для развёртывания нейронных сетей глубокого обучения для различных устройств Intel, будь то процессор, встроенная графика, вентильная матрица, или процессоре машинного зрения\cite{bib:OpenVINO_Product_Page}.
	
		\subsubsection{Структура OpenVINO}
		
			Набор инструментов OpenVINO состоит из нескольких компонентов: (также показано на рисунке \ref{fig:OpenVINO_Structure})
			
			\begin{figure}[h]
				\center{\includegraphics[width=1\linewidth]{OpenVINO_Structure.png}}
				\caption{Структура OpenVINO.}
				\label{fig:OpenVINO_Structure}
			\end{figure}
			
			Intel Deep Learning Deployment Toolkit - это набор инструментов для разработчиков, который позволяет развертывать предварительно обученные углубленные	модели обучения через интерфейс высокого уровня. Инструментарий поддерживает выполнение на четырёх типах устройств:
			
			\begin{itemize}
				\item Графический процессор (GPU) - это специализированная электронная схема, предназначенная для быстрой манипуляции с памятью для ускорения создания изображений в буфере кадров, предназначенном для вывода на устройство отображения\cite{bib:GPU}.
				\item Центральный процессор (СPU), также называемый центральным или главным процессором, представляет собой электронную схему внутри	компьютера, которая выполняет инструкции компьютерной программы, выполняя основную арифметику, логику, управляющие и входные / выходные (I/O) операции задающимися инструкциями\cite{bib:CPU}.
				\item Процессор машинного зрения (VPU) является новым классом микропроцессоров; это особый тип ускорителя искусственного интеллекта, предназначенный для ускорения выполнения задач машинного зрения\cite{bib:VPU}.
				\item Программируемая пользователем вентильная матрица (FPGA) - это интегральная схема, разработанная для конфигурирования пользователем или	инженером непосредственно после изготовления - по этой причине возник термин <<программируемый на месте>>\cite{bib:FPGA}.
			\end{itemize} 
		
			При работе с компьютерным зрением инструментарий OpenVINO нацелена на использовании OpenCV и OpenVX. Набор инструментов OpenVINO также включает в себя большой набор предварительно обученных моделей с глубоким обучением. 
			
			Мы использовали Intel Neural Compute Stick 2 на основе графического процессора Intel Movidius Myriad X, который принадлежит к классу процессоров машинного зрения. Это оборудование, OpenVINO и встроенное в VPU программное обеспечение предназначены для механизма вывода нейронной сети в реальном времени.
		
		\subsubsection{Оптимизатор моделей нейронных сетей}
		
			Чтобы успешно использовать предварительно глубокую обученную нейронную сеть, необходимо преобразовать ее из привычного формата, используемого в средах глубокого обучения, таких как TensorFlow, Caffee, ONNX в оптимизированную модель IR, которая состоит из файлов формата BIN и XML. Для такого преобразования можно использовать включенную в комплект программу Model Optimizer. Типовой рабочий процесс развертывания обученной модели глубокого обучения показан на рисунке \ref{fig:Model_Optimizer_Structure}\cite{bib:Model_Optimizer_Dev_Guide}.
			
			\begin{figure}[h]
				\center{\includegraphics[width=1\linewidth]{Model_Optimizer_Structure.png}}
				\caption{Типовой рабочий процесс для развертывания предварительно обученной модели}
				\label{fig:Model_Optimizer_Structure}
			\end{figure}
		
		\subsubsection{Концепт механизма вывода}
		
			Нам нужно взять предварительно обученную модель и подготовить ее к выводу с помощью специального программного обеспечения - оптимизатора модели от OpenVINO.
			
			Оптимизатор выполняет различные виды манипуляций с моделями, оптимизирует их и преобразует в IR-формат. Все эти манипуляции не зависят от аппаратного обеспечения, но результат OpenVINO может быть воспроизведен на различных устройствах\cite{bib:Deep_Learning_Computer_Vision}.	
			
			Inference Engine (механизм вывода) - это некоторое API, предоставляющее вывод оптимизированных предварительно обученных нейронных сетей, работающих в реальном времени. Оно является общим для всех аппаратных устройств и поддерживает такие языки программирования, как C++ и Python.
			
			Механизм вывода находится в прошивке самого MYRIAD (процессор машинного зрения).
			
			Таким образом, логический механизм обработки имеет разные плагины для каждого из поддерживаемых устройств. Когда разработчик приложения пользуется этим API, вызывая соответствующие функции, он должен указать устройство, на котором должна работать его модель нейронной сети.	Механизм логического вывода будет выбирать необходимый плагин и, следовательно, использовать правильную аппаратную реализацию функций, необходимых для работы нейронной сети (например, умножение на центральном процессоре выполняется при помощи команды ассемблера, а на видеокарте для этого уже понадобится команда из OpenCL).
			
			Наше приложение, распознающие лица берёт кадр с видеокамеры и отправляет его в Inference Engine Common API. Механизм Вывода Intel подаёт на вход нейронной сети полученный кадр и на выходе мы получаем параметры, которые мы используем для отрисовки распознанных образов. Структура Механизма Вывода Intel показана на рисунке \ref{fig:Inference_Engine}\cite{bib:Intel_CV_School}.
			
			\begin{figure}[h]
				\center{\includegraphics[width=1\linewidth]{Inference_Engine.png}}
				\caption{Структура Механизма Вывода}
				\label{fig:Inference_Engine}
			\end{figure}
		
		\subsubsection{Препроцессинг моделей}
		
			Процесс работы с использованием плагина Inference Engine на нашем устройстве (MYRIAD) выглядит так, как показано на рисунке \ref{fig:End_To_End_Workflow}.
			
			\begin{figure}[h]
				\center{\includegraphics[width=1\linewidth]{End_To_End_Workflow.png}}
				\caption{Рабочий процесс.}
				\label{fig:End_To_End_Workflow}
			\end{figure}
			
			Перед отправкой нейронной сети определенному плагину, который принимает оптимизированные нейронные сети в качестве входа от оптимизатора моделей, она проходит несколько этапов оптимизации:
			
			\begin{enumerate}
				\item Оптимизация на уровне нейронной сети: это включает в себя отображение операций, используемых в нейронной сети к архитектуре конкретного целевого устройства для запуска. Выполняя этот шаг заранее, Механизм Вывода улучшает производительность и минимизирует время обработки, так как этот шаг не придётся делать во время непосредственной работы нейронной сети.
				\item Оптимизация на уровне памяти: этот шаг заключается в переупорядочивании данных, размещаемых в памяти для соответствия некоторым особым требованиям к целевым устройствам.
				\item Оптимизация на уровне ядра. Механизм Вывода выбирает правильную реализацию команд, которая лучше всего подходит для данного набора инструкций целевой архитектуры.
			\end{enumerate}	
	
	\subsection{Запуск распознавания лиц}
	
		Общая схема работы приложения изображена на рисунке \ref{fig:Integration_Process}\cite{bib:Integrate_IE_New_API}.
		
		\begin{figure}[h]
			\center{\includegraphics[width=1\linewidth]{Integration_Process.png}}
			\caption{Общая схема работы приложения.}
			\label{fig:Integration_Process}
		\end{figure}
	
		\subsubsection{Использованные модели нейронной сети}
		
			Чтобы продемонстрировать преимущества Neural Compute Stick 2 в разрабатываемом мобильном роботе, мы использовали предварительно обученные модели, которые могут работать параллельно в механизме логического вывода, такие как: face-detection-adas-0001, age-gender-recognition-retail-0013, head-pose-estimation-adas-0001, emotions-recognition-retail-0003.
			
			\begin{itemize}
				\item Модель распознавания лиц (face-detection-adas-0001) является основной моделью. Она позволяет идентифицировать лица на изображении, включает в себя данные глубокую обученную нейронную сеть, позволяющая выполнить объем вычислений для свёрточного блока 3x3. Эта сеть имеет 252 слоя\cite{bib:Face_Detect_Desc}.
				\item Модель распознавания пола и возраста (age-gender-recognition-retail-0013) - это свёрточная нейронная сеть для одновременного распознавания возраста и пола. Сеть может распознавать возраст людей в диапазоне [18, 75] лет и имеет 32 слоя\cite{bib:Age_Gender_Desc}.
				\item Модель оценки позы головы (head-pose-estimation-adas-0001) - это сеть оценки состояния головы, основанная на архитектуре глубокой свёрточной нейронной сети. Угловые регрессионные слои представляют собой свёртки, а нормы пакетов полностью связаны с одним выходом. Эта сеть имеет 43 слоя\cite{bib:Head_Pose_Desc}.
				\item Модель распознавания эмоций (emotions-recognition-retail-0003) представляет собой полностью свёрточную сеть для распознавания пяти эмоций («нейтральная», «счастливая», «грустная», «удивительная», «гнев»). Сеть имеет 54 слоя\cite{bib:Emotion_Recog_Desc}.
			\end{itemize}
		
		\subsubsection{Код}
		
			Для обработки изображений в реальном времени нам потребуется использовать открытую библиотеку компьютерного зрения OpenCV. VideoCapture - это
			класс C++, предназначенный для захвата кадров с камеры или потокового видео\cite{bib:CV_Video_Capture}.
			
			\begin{minted}[breaklines,linenos]{c++}
cv::VideoCapture cap;
			\end{minted}
			
			Далее, мы пытаемся открыть поток, чтобы прочитать первый кадр из камеры и если произошла ошибка или кадр ничего не содержит, то прерываем программу.
			
			\begin{minted}[breaklines,linenos]{c++}
throw std::logic error("Произошла ошибка при открытии потока с камеры");
			\end{minted}
			
			Первым шагом программы будет загрузка аппаратного плагина MYRIAD в Inference Engine. Как упомянуто выше - это необходимый шаг для правильной обработки нейронной сети на нужном устройстве. В нашем случае это Intel Neural Compute Stick 2 (с кодовым названием MYRIAD). 
			
			PluginDispatcher - это класс C++, который выбирает нужный плагин, то есть набор API для механизма вывода, чтобы
			получить результаты работы нейронных сетей на конкретном аппаратном обеспечении\cite{bib:Using_IE_API_Legacy}.
			
			\begin{minted}[breaklines,linenos]{c++}
//Получаем плагин по имени из Inference Engine класса PluginDispatcher.
InferenceEngine::InferencePlugin plugin = InferenceEngine::PluginDispatcher().getPluginByDevice("MYRIAD");
			\end{minted}
			
			Вторым шагом станет чтение IR моделей и загрузка их в MYRIAD:
			
			\begin{minted}[breaklines,linenos]{c++}
InferenceEngine::CNNNetReader netReader;
// Загружаем файл, описывающий топологию нейронной сети.
netReader.ReadNetwork("face-detection-adas-0001.xml");
// Загружаем файл, описывающий веса для нейронной сети.
netReader.ReadWeights("face-detection-adas-0001.bin");
// Получаем готовую глубокую свёрточную нейронную сеть.
InferenceEngine::CNNNetwork cnNet = netReader.getNetwork();
// Загружаем нейронную сеть в плгин и готовим её к работе в присоединнёном устройстве MYRIAD.
InferenceEngine::ExecutableNetwork net = plugin.LoadNetwork(cnNet);

// Повторяем эти действия для другой нейронной сети, определяющей положение головы в пространстве.
InferenceEngine::CNNNetReader netReaderHeadPose;
// Загружаем файл, описывающий топологию нейронной сети.
netReaderHeadPose.ReadNetwork("head-pose-estimation-adas-0001.xml");
// Загружаем файл, описывающий веса для нейронной сети.
netReaderHeadPose.ReadWeights("head-pose-estimation-adas-0001.bin");
// Получаем готовую глубокую свёрточную нейронную сеть.
InferenceEngine::CNNNetwork cnNetHeadPose = netReaderHeadPose.getNetwork();
// Загружаем нейронную сеть в плагин и готовим её к работе в присоединнёном устройстве MYRIAD.
InferenceEngine::ExecutableNetwork netHeadPose = plugin.LoadNetwork(cnNetHeadPose);

// Похожие действия производим для моделей age-gender-recognition-retail-0013 и emotions-recognition-retail-0003.	
			\end{minted}
			
			Третьим шагом станет выполнения бесконечного цикла, в котором производим вычисления и показываем результат пользователю на экран:
			
			\begin{minted}[breaklines,linenos]{c++}
// В этой структуре храним результаты распознавания лиц.
struct Result {
	// Вероятность того, что лицо распознано верно.
	float confidence;
	// Позиция лица, представленная прямоугольной рамкой.
	cv::Rect location;
}

// В этой структуре храним результаты распознавания позы головы.
struct ResultsHeadPose {
	float angle r;
	float angle p;
	float angle y;
};

// В этой структуре храним указатель на тип структуры, конструктор и определяем методы для работы с различными данными.
struct Face {
	using Ptr = std::shared_ptr<Face>;
	explicit Face(size_t id, cv::Rect& location); // Принимает id и местоположение.
	void updateHeadPose(struct ResultsHeadPose values); // Принимает значения положения головы.
}

// Массивы структур для хранения данных.
std::vector <Result> results;
std::vector <ResultsHeadPose> resultsHeadPose;

// Основной и бесконечный цикл приложения. Каждая итерация данного цикла определяет кадр с результатами вычислений.
while (true) {

	// Очищаем до этого распознанные лица.
	results.clear();
	// Объявляем указатель на будущий кадр.
	cv::Mat *frame;
	// Из VideoCapture получаем следующий кадр, а результат записываем в frame.
	cap.read(frame);
	
	// Создаём запрос в Inference Engine.
	InferenceEngine::InferRequest::Ptr *request = net.CreateInferRequestPtr();
	// Из сформированного запроса получаем ссылку на объект, в который сложим наши входные данные - кадр из камеры.
	Blob::Ptr inputBlob = request->GetBlob();
	// Из предыдущего объекта получаем указатель на буффер, в который и сложим выходные данные, затем преобразуем буффер к нужному формату - указатель на float.
	float* detections = inputBlob.buffer().as<float*>();
	// Вызываем функцию, принимающую кадр и указатель на объект Blob. После выполнения функции в буфере появятся данные о распознавании и их можно начать вытаскивать и обрабатывать.
	matU8ToBlob<uint8_t>(frame , &inputBlob);
	
	// Данные получены. Начинаем обрабатывать.
	for (int i = 0; i < max; i++) {
	
		// Создаём структуру и складываем туда информацию о найденных лицах. Нам пригодится местоположение лица на кадре и вероятность правильного распознавания.
		Result result;
		result.confidence = detections[i * objectSize + 2];
		result.location.x = static cast<int>(detections[i * objectSize + 3] * width);
		result.location.y = static cast<int>(detections[i * objectSize + 4] * height);
		result.location.width = static cast<int>(detections[i * objectSize + 5] * width - result.location.x);
		result.location.height = static cast<int>(detections[i * objectSize + 6] * height - result.location.y);
		
		//Если вероятность слишком мала, то лицо не добавляем и идём на следующую итерацию смотреть следующие объекты, похожие на лица.
		if (result.confindence <= threshold ) 
			continue;
		// В другом случае добавляем.
		results.push_back(result);
		
		//Лицо распознали. Теперь таким же образом получим положение головы, воспользовавшись соответствующей нейронной сетью, запущенной на том же устройстве MYRIAD X.
		// Создаём запрос в Inference Engine.
		request = netHeadPose.CreateInferRequestPtr();
		
		// Из сформированного запроса получаем ссылки на объекты, в который сложим наши входные данные - кадр из камеры. Каждая ссылка соответствует своей координате. Далее из этих ссылок просто вытащим число и запишем в результат.
		Blob::Ptr angleR = request->GetBlob("angle r fc");
		Blob::Ptr angleP = request->GetBlob("angle p fc");
		Blob::Ptr angleY = request->GetBlob("angle y fc");
		ResultsHeadPose resultHeadPose = {
			angleR->buffer().as<float*>()[i],
			angleP->buffer().as<float*>()[i],
			angleY->buffer().as<float*>()[i]
		};
		resultsHeadPose.push_back(resultHeadPose);
		
		// Похожие действия повторяем и для остальных нейронных сетей.
		<...>
	}

	//Счётчик лиц, присвающий каждому уникальный номер.
	size_t id = 0;

	// Формируем конечные данные и показываем на кадре.
	for(int i = 0; i < results.size(); i++) {
	
		// Получаем объект класса, описывающий лица.
		Face::Ptr face = std::make_shared<Face>(id++, rect);
		// И передаём туда положение головы и прочие распознанные ранее параметры.
		face->updateHeadPose(resultsHeadPose[i]);
		<...>

		// В окне пользовательского вывода рисуем прямоугольник вокруг лица.
		cv::rectangle(frame, rect, cv::Scalar(255 , 0 , 0), 1);
		// Над лицом отображаем извлечённую из всех нейронных сетей информацию в виде текста.
		cv::putText(frame, face->sex + face->age + face->emotion, cv::Point2f(results[i].location.x , results[i].location.y), cv::FONT_HERSHEY_COMPLEX_SMALL, 1.5, cv::Scalar (255, 0, 0), 2);
		
		// Находим центр лица для отрисовки в центре визуализацию текущего положения головы.
		cv::Point3f center(results[i].location.x + results[i].location.width / 2, results[i].location.y + results[i].location.height / 2, 0.0f);
		// Отрисовку визуализации текущего положения головы отдаём в другую большую функцию.
		drawHeadPose(frame, center, resultsHeadPose[i]);
	}
}
			\end{minted}
			
		\subsubsection{Результат}
		
			На рисунке \ref{fig:Face_Detection_Examples} можно видеть результат работы программы.
			
			\begin{figure}[H]
				\begin{minipage}[h]{0.47\linewidth}
					\center{\includegraphics[width=1\linewidth]{Face_Detection_1.JPEG}} \hspace{0.1cm} \\
				\end{minipage}
				\hfill
				\begin{minipage}[h]{0.47\linewidth}
					\center{\includegraphics[width=1\linewidth]{Face_Detection_2.png}} \hspace{0.1cm} \\
				\end{minipage}
				\vfill
				\begin{minipage}[h]{0.47\linewidth}
					\center{\includegraphics[width=1\linewidth]{Face_Detection_3.png}} \\
				\end{minipage}
				\hfill
				\begin{minipage}[h]{0.47\linewidth}
					\center{\includegraphics[width=1\linewidth]{Face_Detection_4.png}} \\
				\end{minipage}
				\caption{Примеры работы программы.}
				\label{fig:Face_Detection_Examples}
			\end{figure}
		
			При решении данной задачи достигнута отметка 18 кадров в секунду. Для достижения наиболее лучших результатов мы можем использовать два или более Intel Neural Compute Stick 2. 
			
			FPS недостаточно велик, однако, учитывая количество обнаруживаемых параметров, это нормальный результат. На производительность также влияет визуализация положения головы в пространстве - это достаточно сложная задача для механизма вывода. Если мы исключим некоторые характеристики, то можно сказать, что Raspberry Pi 3 Model B и Intel Neural Compute Stick 2 могут обнаруживать лица в режиме реального времени.
	
	\begin{comment}
	\subsection{Запуск распознавания объектов}
	
		Код для распознавания объектов будем писать на языке Python для демонстрации возможностей OpenVINO.
	
		Поставим целью распознать объекты следующих категорий:
		
		\begin{minted}[breaklines,linenos]{python}
LABELS = [['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'], ['background', 'face']]
		\end{minted}
		
		\subsubsection{Принцип работы MobileNet-SSD}
		
			Глубокая свёрточная нейронная сеть, которую будем использовать для данной задачи обнаружения и распознавания - это MobileNet-SSD, предварительно подготовленный набор данных, который мы можем получить из сети Интернет.	
			
			SSD (Single Shot Detector) - фреймворк, целью которого является локализация (отслеживание, ограничивающие рамки) и мгновенная классификация объекта. Подход SSD основан на свёрточной сети с прямой связью, которая производит оценку ограничивающих блоков фиксированного размера и устанавливает вероятности наличия экземпляров каких-либо объектов в этих блоках. После этого шага для каждого блока следует взять объект с максимальной вероятностью, таким образом вынеся вердикт о том, что находится в данной области.
			
			Ранние сетевые уровни основаны на стандартной архитектуре, используемой для классификации изображений высокого качества (усеченной до любых классификационных слоев), которая называется базовой сетью. Модель SSD добавляет несколько слоев свертки для объектов в конец базовой сети, которые предсказывают сдвиги по умолчанию для блоков разных масштабов, соотношений сторон и связанных с ними доверительных отношений. Общая схема отражена на рисунке \ref{fig:SSD_Scheme}.
			
			\begin{figure}[h]
				\center{\includegraphics[width=1\linewidth]{SSD_Scheme.png}}
				\caption{Общая схема SSD.}
				\label{fig:SSD_Scheme}
			\end{figure}
			
			MobileNet - это свёрточная архитектура нейронных сетей, которая применяется на устройствах с ограниченной вычислительной мощностью. Структура MobileNet построена на разделенных по глубине свертках, за исключением первого уровня, который является полной сверткой. Нормальная свёртка заменяется глубокой свёрткой, за которой следует точечная свёртка, которая называется отделимой глубиной свёрткой.
			Это значительно сокращает количество параметров по сравнению с сетью с обычными свёртками и приводит к значительному сокращению общего числа операций с плавающим умножением, что выгодно на таких мобильных решениях\cite{bib:Driaba_NIR}.
			
		\subsubsection{Принцип работы приложения}
		
			В финальной реализации алгоритм работает следующим образом: основой является Raspberry PI 3 Model B, которая принимает видеосигнал, затем сигнал делится на кадры, каждый кадр предварительно обрабатывается с использованием библиотеки OpenCV, сжимается и при помощи плагина Inference Engine передается в подключаемый модуль Intel Neural Compute Stick 2. После обработки нейронной сети (обнаружение, присутствие или отсутствие, отслеживание с соответствующим кадром и подписью) данные используются для наложения кадра на исходное изображение, которое затем отображается на экране\cite{bib:Driaba_NIR}.
		
		\subsubsection{Код}
		
			Как и было сказано ранее, после работы оптимизатора моделей, модель начинает располагаться в 2 файлах.
			
			Структура модели нейронной сети хранится в формате XML:
			\begin{minted}[breaklines,linenos]{python}
self.model_xml = "./lrmodel/MobileNetSSD/MobileNetSSD_deploy.xml"
			\end{minted}
			
			Веса моделей хранятся в другом формате:
			\begin{minted}[breaklines,linenos]{python}
self.model_bin = "./lrmodel/MobileNetSSD/MobileNetSSD_deploy.bin"
			\end{minted}
			
			После подготовки всех моделей их уже можно использовать в приложении, выполнив системные вызовы API Inference Engine.
			Первый шаг - импортировать плагин для MYRIAD:
			\begin{minted}[breaklines,linenos]{python}
self.plugin = IEPlugin(device="MYRIAD")
self.net = IENetwork(model=self.model_xml, weights=self.model_bin)
self.input_blob = next(iter(self.net.inputs))
			\end{minted}
			
			Перед непосредственным вызовом API Inference Engine вы должны сначала обработать полученные изображения, сжать их. Это делается с помощью открытой библиотеки OpenCV (метод image\_preprocessing).
			После предварительной обработки вы уже можете вызывать методы API, заполнив специальную структуру числами:
			\begin{minted}[breaklines,linenos]{python}
self.exec_net.start_async(request_id=reqnum, inputs={self.input_blob: prepimg})
			\end{minted}
			После выполнения всех асинхронных запросов, структура проверяется на наличие найденных объектов. Если на изображении обнаружен объект, то с помощью OpenCV вокруг него рисуется рамка с надписью (рис. 8).
			
			Полный код программы представлен ниже\cite{bib:Driaba_NIR}:
			
			\begin{minted}[breaklines,linenos]{python}
if __name__ == '__main__':

try:
# Start streaming process
p = mp.Process(target=cam_thread, args=(...), daemon=True)
p.start()
processes.append(p)

# Start the recognition process on the stick
p = mp.Process(target=inferencer, args=(...), daemon=True)
p.start()
processes.append(p)

# main thread does not finish
while True:
sleep(1)

# complete all processes
finally:
for p in range(len(processes)):
processes[p].terminate()

def cam_thread(labels, results, frame_buffer, number_of_camera):
# create camera object
cam = cv2.VideoCapture(number_of_camera)
cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)

while True:
# USB camera reading stream
image = cam.read()

if frame_buffer.full():
frame_buffer.get()

frame_buffer.put(image.copy())

if not results.empty():
res = results.get(False)
image_draw = overlay_on_image(image, res, labels)
last_results = res
else:
image_draw = overlay_on_image(image, last_results, labels)

cv2.imshow(window_name, image_draw)

def async_infer(ncsworker):
while True:
ncsworker.predict_async()

def inferencer(results, frameBuffer, width, height, number_of_ncs):
# Init infer threads
threads = []
for devid in range(number_of_ncs):
thworker = threading.Thread(target=async_infer, args=(NcsWorker(...)))
thworker.start()
threads.append(thworker)
for th in threads:
th.join()
# l = Search list, x = Search target value
def searchlist(l, x):
if x in l:
return l.index(x)
else:
return -1

class NcsWorker(object):

def predict_async(self):

# Image preprocessing
prepimg = self.image_preprocessing(self.frameBuffer.get())
reqnum = searchlist(self.inferred_request, 0)

if reqnum > -1:
# Start the recognition process
self.exec_net.start_async(request_id=reqnum, inputs={self.input_blob: prepimg})
self.inferred_request[reqnum] = 1
self.inferred_cnt += 1
if self.inferred_cnt == sys.maxsize:
self.inferred_request = [0] * self.num_requests
self.heap_request = []
self.inferred_cnt = 0
heapq.heappush(self.heap_request, (self.inferred_cnt, reqnum))

cnt, dev = heapq.heappop(self.heap_request)

if self.exec_net.requests[dev].wait(0) == 0:
self.exec_net.requests[dev].wait(-1)
out = self.exec_net.requests[dev].outputs["detection_out"].flatten()
self.results.put([out])
self.inferred_request[dev] = 0
else:
heapq.heappush(self.heap_request, (cnt, dev))

			\end{minted}
		
		\subsubsection{Результат}
			
			При разрешении 320х240 программа может выдавать стабильные 30 FPS. При увеличении разрешения до 1280x720 (то есть HD) производительность падает до 9 FPS, т.к довольно большую часть ресурсов на Raspberry Pi 3 Model B занимает отрисовка поступившего видео-сигнала. Для нормального функционирования робота, с получением изображений в реальном времени в хорошем разрешении, одной Intel Neural Compute Stick 2 недостаточно. Производительность можно улучшить, используя от 2 до 4 таких устройств. Пример работы программы можно увидеть на рисунке \ref{fig:Object_Detection}.
		
			\begin{figure}[H]
				\begin{minipage}[h]{0.32\linewidth}
					\center{\includegraphics[width=1\linewidth]{Object_Detection_1.png}} \\
				\end{minipage}
				\hfill
				\begin{minipage}[h]{0.32\linewidth}
					\center{\includegraphics[width=1\linewidth]{Object_Detection_2.png}} \\
				\end{minipage}
				\hfill
				\begin{minipage}[h]{0.32\linewidth}
					\center{\includegraphics[width=1\linewidth]{Object_Detection_3.png}} \\
				\end{minipage}
				\caption{Пример работы программы.}
				\label{fig:Object_Detection}
			\end{figure}
		
			В данных примерах бутылка была распознана лучше всего, если она была расположена близко к камере. Объект <<стул>> время от времени исчезал, из списка распознанных предметов, а вот диван всё время определялся (хотя в рамке был лишь частично). Монитор (планшетный компьютер) распознался лучше всего: проблем с данным объектом не наблюдалось\cite{bib:Driaba_NIR}. 
			
			\end{comment}

\section{Заключение}

	Подводя итоги работы, можно сказать, что отечественные аппаратные решения от компании Элвис в области компьютерного зрения на данный момент находятся в <<плачевном>> состоянии и пока что для разработки нашего мобильного робота мы вынуждены использовать зарубежную разработку от Raspberry Foundation и компании Intel, а такое партнёрство с зарубежными коллегами при попытках внедрения данных решений в государственной сфере на вряд-ли будет одобрено. Однако, это ни сколь не помешало решению нашей задачи и наш робот сможет распознавать лица.
	
\newpage

\begin{thebibliography}{9}
	\bibitem{bib:Smart_Payment_China}People's Daily Online. Is facial recognition the future of smart payment in China? 
	\newblock --- The Telegraph. \url{https://www.telegraph.co.uk/peoples-daily-online/science/facial-recognition/}
	
	\bibitem{bib:Deep_Conv_Network_Wiki}Свёрточная нейронная сеть. 
	\newblock --- Википедия.
 	\url{https://ru.wikipedia.org/wiki/%D0%A1%D0%B2%D1%91%D1%80%D1%82%D0%BE%D1%87%D0%BD%D0%B0%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C}
	
	\bibitem{bib:Integrate_IE_New_API}Integrate the Inference Engine New Request API with Your Application.
	\newblock --- Intel. \url{https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Integrate_with_customer_application_new_API.html}
	
	\bibitem{bib:Raspberry_PI_Product_Page}Raspberry Pi 3 Model B.
	\newblock --- RASPBERRY PI FOUNDATION. \url{https://www.raspberrypi.org/products/raspberry-pi-3-model-b/}
	
	\bibitem{bib:Raspbian_Specs}Raspbian.
	\newblock --- Википедия. \url{https://ru.wikipedia.org/wiki/Raspbian}
	
	\bibitem{bib:Raspberry_Face_Recognition}Adrian Rosenbrock. Raspberry Pi Face Recognition.
	\newblock --- PyImageSearch. \url{https://pyimagesearch.com/2018/06/25/raspberry-pi-face-recognition/}
	
	\bibitem{bib:OpenVINO_Product_Page}Intel Distribution of OpenVINO Toolkit.
	\newblock --- Intel. \url{https://software.intel.com/ru-ru/openvino-toolkit}
	
	\bibitem{bib:GPU}Графический процессор.
	\newblock --- Википедия. \url{https://ru.wikipedia.org/wiki/%D0%93%D1%80%D0%B0%D1%84%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80}
	
	\bibitem{bib:CPU}Центральный процессор.
	\newblock --- Википедия. \url{https://ru.wikipedia.org/wiki/%D0%A6%D0%B5%D0%BD%D1%82%D1%80%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80}
		
	\bibitem{bib:VPU}Процессор машинного зрения.
	\newblock --- Википедия. \url{https://ru.wikipedia.org/wiki/%D0%A6%D0%B5%D0%BD%D1%82%D1%80%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80}
		
	\bibitem{bib:FPGA}Программируемая пользователем вентильная матрица.
	\newblock --- Википедия. \url{https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D1%83%D0%B5%D0%BC%D0%B0%D1%8F_%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D0%B5%D0%BC_%D0%B2%D0%B5%D0%BD%D1%82%D0%B8%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0}
		
	\bibitem{bib:Model_Optimizer_Dev_Guide}Model Optimizer Developer Guide.
	\newblock --- Intel. \url{https://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html}	
	
	\bibitem{bib:Deep_Learning_Computer_Vision}Deep Learning For Computer Vision.
	\newblock --- Intel. \url{https://software.intel.com/en-us/openvino-toolkit/deep-learning-cv}
	
	\bibitem{bib:Intel_CV_School}Обзор OpenVINO/ Open Model Zoo.
	\newblock --- Intel. \url{https://delta-course.org/Intel-CV-School}
	
	\bibitem{bib:Face_Detect_Desc}face-detection-adas-0001.
	\newblock --- Intel. \url{https://docs.openvinotoolkit.org/latest/_face_detection_adas_0001_description_face_detection_adas_0001.html}
	
	\bibitem{bib:Age_Gender_Desc}age-gender-recognition-retail-0013.
	\newblock --- Intel. \url{https://docs.openvinotoolkit.org/latest/_age_gender_recognition_retail_0013_description_age_gender_recognition_retail_0013.html}
	
	\bibitem{bib:Head_Pose_Desc}head-pose-estimation-adas-0001.
	\newblock --- Intel. \url{https://docs.openvinotoolkit.org/latest/_head_pose_estimation_adas_0001_description_head_pose_estimation_adas_0001.html}
	
	\bibitem{bib:Emotion_Recog_Desc}emotion-recognition-retail-0003.
	\newblock --- Intel. \url{https://docs.openvinotoolkit.org/latest/_emotions_recognition_retail_0003_description_emotions_recognition_retail_0003.html}
	
	\bibitem{bib:CV_Video_Capture}cv::VideoCapture Class Reference.
	\newblock --- OpenCV. \url{https://docs.opencv.org/3.1.0/d8/dfe/classcv_1_1VideoCapture.html}
	
	\bibitem{bib:Using_IE_API_Legacy}Integrate the Inference Engine API with Your Application (Legacy).
	\newblock --- Intel. \url{https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Integrate_with_customer_application.html}
	
	\bibitem{bib:Elise_CPU_Desc}Процессор ELISE для систем компьютерного зрения.
	\newblock --- Элвис. \url{https://multicore.ru/index.php?id=1406}
	
	\bibitem{bib:Buildroot_Wikipedia}Buildroot.
	\newblock --- Википедия. \url{https://en.wikipedia.org/wiki/Buildroot}
	
	\bibitem{bib:Chuprikov_NIR}Чуприков Вячеслав. Разработка ПО для первичной обработки видеоинформации на основе системы «ЭЛИЗ-3D».
	\newblock --- Кафедра Информационных систем и компьютерного моделирования. Волгоградский Государственный Университет. г. Волгоград, 2019 г.
	
	\bibitem{bib:Viola-Jones_Wikipedia}Viola–Jones object detection framework.
	\newblock --- Википедия. \url{https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework}
		
	\bibitem{bib:Viola-Jones_Wikipedia_Ru}Метод Виолы — Джонса.
	\newblock --- Википедия. \url{https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%92%D0%B8%D0%BE%D0%BB%D1%8B_%E2%80%94_%D0%94%D0%B6%D0%BE%D0%BD%D1%81%D0%B0}
		
	\bibitem{bib:Haar_Wikipedia}Признаки Хаара.
	\newblock --- Википедия. \url{https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%B8%D0%B7%D0%BD%D0%B0%D0%BA%D0%B8_%D0%A5%D0%B0%D0%B0%D1%80%D0%B0}
		
	\bibitem{bib:OpenVX_Wikipedia}OpenVX.
	\newblock --- Википедия. \url{https://en.wikipedia.org/wiki/OpenVX}		
	
	\bibitem{bib:OpenVX_Habr}Виктор Ерухимов. OpenVX: стандарт компьютерного зрения.
	\newblock --- Хабр. \url{https://habr.com/ru/company/intel/blog/204236/}
	
	%\bibitem{bib:Driaba_NIR}Александр Дряба. Распознавание объектов на встраиваемых системах.
	%\newblock --- Кафедра компьютерных наук и экспериментальной математики. Волгоградский Государственный Университет. г. Волгоград, 2019 г.
	
\end{thebibliography}

\end{document}
